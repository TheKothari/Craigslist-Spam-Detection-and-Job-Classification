{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\nfrom keras.models import Sequential\\nfrom keras.layers.recurrent import LSTM, GRU\\nfrom keras.layers.core import Dense, Activation, Dropout\\nfrom keras.layers.embeddings import Embedding\\nfrom tensorflow.keras.layers import (\\n    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\\n)\\nfrom keras.utils import np_utils\\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\\nfrom keras.preprocessing import sequence\\nfrom keras.preprocessing.text import Tokenizer\\n\\nfrom keras.callbacks import EarlyStopping'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import packages\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, KMeansSMOTE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "'''import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    ")\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17880 entries, 0 to 17879\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               17880 non-null  int64 \n",
      " 1   title                17880 non-null  object\n",
      " 2   location             17534 non-null  object\n",
      " 3   department           6333 non-null   object\n",
      " 4   salary_range         2868 non-null   object\n",
      " 5   company_profile      14572 non-null  object\n",
      " 6   description          17879 non-null  object\n",
      " 7   requirements         15185 non-null  object\n",
      " 8   benefits             10670 non-null  object\n",
      " 9   telecommuting        17880 non-null  int64 \n",
      " 10  has_company_logo     17880 non-null  int64 \n",
      " 11  has_questions        17880 non-null  int64 \n",
      " 12  employment_type      14409 non-null  object\n",
      " 13  required_experience  10830 non-null  object\n",
      " 14  required_education   9775 non-null   object\n",
      " 15  industry             12977 non-null  object\n",
      " 16  function             11425 non-null  object\n",
      " 17  fraudulent           17880 non-null  int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#reading data\n",
    "df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess\n",
    "# df['text']=df['text'].str.lower()\n",
    "def preprocess(df):\n",
    "    df = df[df.location.notnull()]\n",
    "    df = df[df.function.notnull()]\n",
    "    df= df[df.location.str.contains(\"US,\")] \n",
    "    df['description']=df['description'].str.lower()\n",
    "    return df\n",
    "\n",
    "df = preprocess(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.function.unique()\n",
    "len(df.function.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatiaztion\n",
    "def getLemmText(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['description'] = list(map(getLemmText,df['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>function</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing</td>\n",
       "      <td>food52 , a fast-grow , jame beard award-win on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales</td>\n",
       "      <td>the compani : esri – environ system research i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health Care Provider</td>\n",
       "      <td>job titl : item review managerloc : fort worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>the custom servic associ will be base in phoen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>posit : # url_86fd830a95a64e2b30ceed829e63fd38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>Production</td>\n",
       "      <td>key duti : • rough cut show on adob premier ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>we are activ search for a senior financ analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>Product Management</td>\n",
       "      <td>flite 's saa display ad platform fuel the worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>sr , javascript develop experi : 4-10 year loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>Accounting/Auditing</td>\n",
       "      <td>the payrol account will focu primarili on payr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6704 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    function  \\\n",
       "0                  Marketing   \n",
       "1                      Sales   \n",
       "2       Health Care Provider   \n",
       "3           Customer Service   \n",
       "4     Information Technology   \n",
       "...                      ...   \n",
       "6699              Production   \n",
       "6700       Financial Analyst   \n",
       "6701      Product Management   \n",
       "6702  Information Technology   \n",
       "6703     Accounting/Auditing   \n",
       "\n",
       "                                            description  \n",
       "0     food52 , a fast-grow , jame beard award-win on...  \n",
       "1     the compani : esri – environ system research i...  \n",
       "2     job titl : item review managerloc : fort worth...  \n",
       "3     the custom servic associ will be base in phoen...  \n",
       "4     posit : # url_86fd830a95a64e2b30ceed829e63fd38...  \n",
       "...                                                 ...  \n",
       "6699  key duti : • rough cut show on adob premier ad...  \n",
       "6700  we are activ search for a senior financ analys...  \n",
       "6701  flite 's saa display ad platform fuel the worl...  \n",
       "6702  sr , javascript develop experi : 4-10 year loc...  \n",
       "6703  the payrol account will focu primarili on payr...  \n",
       "\n",
       "[6704 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getStemmText(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    ps = PorterStemmer()\n",
    "    tokens=[ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['description'] = list(map(getStemmText,df['description']))\n",
    "df_text = pd.DataFrame({'function': df.function.tolist() , 'description': df.description.tolist()})\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['description']= df_text['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6704 entries, 0 to 6703\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   function     6704 non-null   object\n",
      " 1   description  6704 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 104.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:03, 106807.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading Glove Embedding\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.50d.txt', encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    value = line.split()\n",
    "    word = value[0]\n",
    "    coef = np.asarray(value[1:], dtype='float32')\n",
    "    embeddings_index[word] = coef\n",
    "f.close()\n",
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 2000\n",
    "MAX_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-76a703bd88f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoded_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# convert integers to dummy variables (i.e. one hot encoded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdummy_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_text.function)\n",
    "encoded_Y = encoder.transform(df_text.function)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_text.description, dummy_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(list(train_x) + list(test_x))\n",
    "\n",
    "xtrain_sequence = tokenizer.texts_to_sequences(train_x)\n",
    "xtest_sequence = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\n",
    "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "max_features=VOCABULARY_SIZE\n",
    "maxlen=MAX_LENGTH\n",
    "model = Sequential()\n",
    "# model.add(Embedding(max_features, 40, input_length=maxlen))\n",
    "model.add(Embedding(len(word_index) + 1,50,weights=[embedding_matrix],input_length=MAX_LENGTH,trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(37))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x, y=train_y, batch_size=512, epochs=10, verbose=1, validation_data=(xtest_padding,test_y ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "def graph_plots(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[‘val_’+string])\n",
    "    plt.xlabel(“Epochs”)\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, ‘val_’+string])\n",
    "    plt.show()\n",
    "\n",
    "graph_plots(history, “accuracy”)\n",
    "graph_plots(history, “loss”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
