{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"stop_words = stopwords.words('english')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import packages\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, KMeansSMOTE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, SeparableConv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    ")\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "'''stop_words = stopwords.words('english')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17880 entries, 0 to 17879\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_id               17880 non-null  int64 \n",
      " 1   title                17880 non-null  object\n",
      " 2   location             17534 non-null  object\n",
      " 3   department           6333 non-null   object\n",
      " 4   salary_range         2868 non-null   object\n",
      " 5   company_profile      14572 non-null  object\n",
      " 6   description          17879 non-null  object\n",
      " 7   requirements         15185 non-null  object\n",
      " 8   benefits             10670 non-null  object\n",
      " 9   telecommuting        17880 non-null  int64 \n",
      " 10  has_company_logo     17880 non-null  int64 \n",
      " 11  has_questions        17880 non-null  int64 \n",
      " 12  employment_type      14409 non-null  object\n",
      " 13  required_experience  10830 non-null  object\n",
      " 14  required_education   9775 non-null   object\n",
      " 15  industry             12977 non-null  object\n",
      " 16  function             11425 non-null  object\n",
      " 17  fraudulent           17880 non-null  int64 \n",
      "dtypes: int64(5), object(13)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#reading data\n",
    "df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess\n",
    "# df['text']=df['text'].str.lower()\n",
    "def preprocess(df):\n",
    "    df = df[df.location.notnull()]\n",
    "    df= df[df.location.str.contains(\"US,\")] \n",
    "    df['description']=df['description'].str.lower()\n",
    "    return df\n",
    "\n",
    "df = preprocess(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatiaztion\n",
    "def getLemmText(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['description'] = list(map(getLemmText,df['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>food52 , a fast-grow , jame beard award-win on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>our client , locat in houston , is activ seek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the compani : esri – environment system resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>job titl : item review managerloc : fort worth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>job overviewapex is an environment consult fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10588</th>\n",
       "      <td>0</td>\n",
       "      <td>flite 's saa display ad platform fuel the worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10589</th>\n",
       "      <td>0</td>\n",
       "      <td>respons : will facilit the recruit and hire pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10590</th>\n",
       "      <td>0</td>\n",
       "      <td>sr , javascript develop experi : 4-10 year loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10591</th>\n",
       "      <td>0</td>\n",
       "      <td>the payrol account will focu primarili on payr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10592</th>\n",
       "      <td>0</td>\n",
       "      <td>experienc project cost control staff engin is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10593 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                        description\n",
       "0          0  food52 , a fast-grow , jame beard award-win on...\n",
       "1          0  our client , locat in houston , is activ seek ...\n",
       "2          0  the compani : esri – environment system resear...\n",
       "3          0  job titl : item review managerloc : fort worth...\n",
       "4          0  job overviewapex is an environment consult fir...\n",
       "...      ...                                                ...\n",
       "10588      0  flite 's saa display ad platform fuel the worl...\n",
       "10589      0  respons : will facilit the recruit and hire pr...\n",
       "10590      0  sr , javascript develop experi : 4-10 year loc...\n",
       "10591      0  the payrol account will focu primarili on payr...\n",
       "10592      0  experienc project cost control staff engin is ...\n",
       "\n",
       "[10593 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getStemmText(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    ps = PorterStemmer()\n",
    "    tokens=[ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['description'] = list(map(getStemmText,df['description']))\n",
    "df_text = pd.DataFrame({'label': df.fraudulent.tolist() , 'description': df.description.tolist()})\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['description']= df_text['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10593 entries, 0 to 10592\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   label        10593 non-null  int64 \n",
      " 1   description  10593 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 165.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12128it [00:00, 20117.64it/s]"
     ]
    }
   ],
   "source": [
    "#Loading Glove Embedding\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.50d.txt', encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    value = line.split()\n",
    "    word = value[0]\n",
    "    coef = np.asarray(value[1:], dtype='float32')\n",
    "    embeddings_index[word] = coef\n",
    "f.close()\n",
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 2000\n",
    "MAX_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_text.description, df_text.label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(list(train_x) + list(test_x))\n",
    "\n",
    "xtrain_sequence = tokenizer.texts_to_sequences(train_x)\n",
    "xtest_sequence = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\n",
    "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 50))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE oversample\n",
    "def smote(train_x, train_y):\n",
    "    smt = KMeansSMOTE(random_state=42, k_neighbors = 72, cluster_balance_threshold = 0.05)\n",
    "    train_x,train_y = smt.fit_resample(train_x,train_y)\n",
    "    return train_x,train_y\n",
    "\n",
    "train_x,train_y = smote(xtrain_padding,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "max_features=VOCABULARY_SIZE\n",
    "maxlen=MAX_LENGTH\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 40, input_length=maxlen))\n",
    "# model.add(Embedding(len(word_index) + 1,50,weights=[embedding_matrix],input_length=MAX_LENGTH,trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(xtrain_padding, y=train_y, batch_size=512, epochs=10, verbose=1, validation_data=(xtest_padding,test_y ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation\n",
    "def graph_plots(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[‘val_’+string])\n",
    "    plt.xlabel(“Epochs”)\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, ‘val_’+string])\n",
    "    plt.show()\n",
    "\n",
    "graph_plots(history, “accuracy”)\n",
    "graph_plots(history, “loss”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
